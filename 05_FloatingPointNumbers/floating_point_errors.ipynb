{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "775fb74b-573f-4358-8efd-cd624c4a3693",
   "metadata": {},
   "source": [
    "# Floating points errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9188ae7-2b2c-487b-a28d-f1ede537197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c400339d-6288-44a8-94d3-937eb1088a3b",
   "metadata": {},
   "source": [
    "> **Problem**\n",
    ">\n",
    ">Why does the following Python code\n",
    ">\n",
    ">```python\n",
    ">0.1 + 0.2 + 0.3 == 0.6\n",
    ">```\n",
    ">\n",
    ">return `False`? Let's try it out for ourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f00363f-9365-4f8d-a790-670995cc1a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.1 + 0.2 + 0.3 == 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aabf84-d694-463f-8d31-1e6f2527ab80",
   "metadata": {},
   "source": [
    "Yep, that does appear strange.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08764935-5eae-486f-b516-4e46360a37cd",
   "metadata": {},
   "source": [
    "## Represening real numbers ($\\mathbb R$) in a computer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e41eb29-0951-49e2-a8cc-32a096dec40f",
   "metadata": {},
   "source": [
    "We learnt that we should represent a real numbers in Python using the type `float`. \n",
    "\n",
    "Computers (and calculators) have a finite amount of memory. Modern computers may have upwards of 4 GB ($4 \\times 10^9$ bytes) of RAM. This memory is used to run your computers operating systems and other applications.\n",
    "\n",
    "Since the total memory available on a computer is finite, so to is the amount of memory (in bytes) availble to represent a real number. Your Python code (as an example of an application) will store many real numbers, for example\n",
    "\n",
    "```python\n",
    "N = 100\n",
    "x = numpy.zeros(N)\n",
    "```\n",
    "\n",
    "requires storing 100 real numbers. For this reason, the amount of memory assigned to represent a real number as `float` is kept as small as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c87af4a-3856-4fca-b7e6-433ca21de9e1",
   "metadata": {},
   "source": [
    "The consequence of using a finite amount of memory to represent a real number via a `float` is twofold:\n",
    "\n",
    "1. The numbers possible to represent in a computer with `float` cannot be arbitrarly large of arbitrarily small.\n",
    "2. There must be gaps between the represented numbers.\n",
    "\n",
    "Points 1. and 2. are fundemental limitations of representing real numbers in a computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcbd676-32b2-458c-80c7-cf82e2270985",
   "metadata": {},
   "source": [
    "### Ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57abfe24-3901-440a-a625-120bda9706ff",
   "metadata": {},
   "source": [
    "The so called \"double precision\" standard (defined by the IEEE-754 arithmetic standard) allows: \n",
    "* numbers as large as $n_\\text{max} = 1.79 \\times 10^{308}$ to be represented;\n",
    "* numbers as small as $n_\\text{min} = 2.23 \\times 10^{-308}$ to be represented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1f9ee-22de-481f-8ce7-a5af87604c1b",
   "metadata": {},
   "source": [
    "If you try to assign a value to a double precision number less than $n_\\text{min}$ *underflow* occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9eccc51-9df8-498f-8143-413a186f34a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.23e-308\n"
     ]
    }
   ],
   "source": [
    "x = 2.23e-308 # This is fine\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59934b20-e17f-4481-a372-96f0cb66e901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23e-308\n"
     ]
    }
   ],
   "source": [
    "x = 1.23e-308 # Also appears to be fine\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b840b0b0-086f-4df8-9c3f-bb59987bdf7e",
   "metadata": {},
   "source": [
    "Hardward engineers use a sub-normal representation for small numbers allow numbers (for double precision to) to actually be as small as $2.5 \\times 10^{-324}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7b3e102-49f4-4888-8ea4-608d40032b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "x = 2.40000000e-324 # This is truncated to zero\n",
    "print(x, type(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05027869-68c8-4a3b-a787-069693e729f1",
   "metadata": {},
   "source": [
    "Here underflow results in the number being truncated to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9ff480-adbb-41c6-9e4e-b24eae8a6fbb",
   "metadata": {},
   "source": [
    "If you try to assign a value to a double precision number greater than $n_\\text{max}$ *overflow* occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f01788cf-bb93-4455-8818-59c35b16556f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.79e+308\n"
     ]
    }
   ],
   "source": [
    "x = 1.79e308 # This is fine\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae30ce-fac2-474d-9b82-dbff2591602c",
   "metadata": {},
   "source": [
    "However exceeding $n_\\text{max}$ results in `x` being assigned a value of `inf`, which means \"infinity\". It is not the true infinity, it is the infinity associated with double precision representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b48ed6b0-58e8-45e7-9c83-f8312acffebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    }
   ],
   "source": [
    "x = 1.799e308\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9a417a-8f7c-49c6-aa49-c94e9cf8f706",
   "metadata": {},
   "source": [
    "### How numbers are stored\n",
    "\n",
    "Python's `float` class uses use a double precision representation.\n",
    "We saw earlier that this is equivalent to NumPy's `float64`.\n",
    "NumPy supports lower precision numbers such as `float32` and `float16`.\n",
    "\n",
    "Numbers in a computer are stored in scientific notation, e.g.\n",
    "$$\n",
    "    +1.12132343678e-64\n",
    "$$\n",
    "\n",
    "The memory (bytes) used to represent a floating point number are partitioned into representing three parts of the number:\n",
    "* Storage for the sign of the number (`+`);\n",
    "* Storage for the exponent (`-64`);\n",
    "* Storage for the decimal digits `1.12132343678` (or mantissa).\n",
    "\n",
    "The `16`, `32` and `64` in `float16, float32, float64` indicate the number of bits used to store the number. There are 8 bits in a byte.\n",
    "\n",
    "For `float16` we have\n",
    "* 1 bit is used for the sign of the number\n",
    "* 5 bits are are used for the exponent;\n",
    "* 10 bits are used for the decimal digits.\n",
    "    - This translates to a precision of 7 decimal digits.\n",
    "\n",
    "For `float32` we have\n",
    "* 1 bit is used for the sign of the number\n",
    "* 8 bits are are used for the exponent;\n",
    "* 23 bits are used for the decimal digits.\n",
    "    - This translates to a precision of approximately 7 decimal digits.\n",
    "\n",
    "For `float64` we have\n",
    "* 1 bit is used for the sign of the number\n",
    "* 11 bits are are used for the exponent;\n",
    "* 32 bits are used for the decimal digits.\n",
    "    - This translates to a precision of approximately 16 decimal digits.\n",
    "\n",
    "Historically computers were shipped with `float32`. Later `float64` become availble. Since a `float64` uses twice as many bits in its representation compared to the original floating point unit (`float32`) they become known as \"double precision\". Recently in ML there is interest in `float16` - following the same naming convention these become known as \"half-precision\". These days `float128` is used and these are referred to as \"quad-precision\" floating point representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e7bb64-8124-446d-bbbe-c66a0fbf7927",
   "metadata": {},
   "source": [
    "Python's `float` class uses use a double precision representation.\n",
    "We saw earlier that this is equivalent to NumPy's `float64`.\n",
    "NumPy supports lower precision numbers such as `float32` and `float16`.\n",
    "The consequence of using a lower precision number representation is the range of possible numbers you can represent is smaller and gaps between representable numbers is larger."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554eb3b8-a537-423f-b448-4fd04d6a7c73",
   "metadata": {},
   "source": [
    "### Gappiness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04205376-b9b0-4d34-a2ac-412a257f228e",
   "metadata": {},
   "source": [
    "The interval of real numbers $[1, 2]$ when represented via double precision is given by the discrete subset\n",
    "\n",
    "$$\n",
    "1, \\, 1 + 2^{-52}, \\, 1 + 2 \\times 2^{-52}, \\, 1 + 3 \\times 2^{-52}, \\, \\dots, \\, 2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b7d3f9-9660-472b-ae8a-aaa3de0949a4",
   "metadata": {},
   "source": [
    "The interval $[2, 4]$ is given by the discrete subset\n",
    "\n",
    "$$\n",
    "2, \\, 2 + 2^{-52}, \\, 2 + 2 \\times 2^{-52}, \\, 2 + 3 \\times 2^{-52}, \\, \\dots, \\, 4\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd57456-682d-477d-a8fb-c9b28225f00b",
   "metadata": {},
   "source": [
    "In a relative sense, the gaps between adjacent numbers is $2^{-52} \\approx 2.22 \\times 10^{-16}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92890e16-499b-4928-8bb9-65b13e299226",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We now what a sense of what the answer to the problem stated at the top of the document is.\n",
    "\n",
    "Think of the problem this way\n",
    "\n",
    "```python\n",
    "float(0.1) + float(0.2) + float(0.3) \n",
    "```\n",
    "\n",
    "We know the `float` representation of numbers contains gaps. This means not every single real number in $\\mathbb R$ can be represented! Hence if `float(0.1)` can only be approximately represented, say within $2.22 \\times 10^{-16}$ and the same is true for `float(0.2)` and `float(0.3)` then when we add them all up we will not end up with a result which is exactly 0.6. We likely have $0.6 + O(10^{-16})$.\n",
    "\n",
    "Lets confirm this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f8216fe-1ad8-434f-a969-084d477775d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result 6.00000000000000088818e-01\n",
      "delta 1.11022302462515654042e-16\n"
     ]
    }
   ],
   "source": [
    "result = float(0.1) + float(0.2) + float(0.3)\n",
    "\n",
    "print('result', ('%1.20e'%result))\n",
    "\n",
    "# Let's compute the difference between what we expected (0.6) and result\n",
    "\n",
    "delta = result - 0.6\n",
    "\n",
    "print('delta', ('%1.20e'%delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b01f693-550d-40b1-823d-61709f470685",
   "metadata": {},
   "source": [
    "Inded the result is not **exactly** 0.6 and the difference is $O(10^{-16})$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45889a46-44f2-4e44-b9b4-319557b7ebcb",
   "metadata": {},
   "source": [
    "## Round-off Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df02e65-0bfd-45d6-8043-8d359b9a1b3e",
   "metadata": {},
   "source": [
    "If numbers are not exactly represented and you perform operations with them, the resulting quantity will also have errors. \n",
    "\n",
    "Take `z = a + b`. If there is a representation error associated with number stored in `a`, and in `b`, `a + b` will have an error. There is the additional which may occur in that the resulting value for `a + b` can also not be exactly represent so another representation error creeps in.\n",
    "\n",
    "The more operations you perform, the worse the error in the final result will become. This is called round-off error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c343fff5-4458-444b-ac7f-b3727642c9d3",
   "metadata": {},
   "source": [
    "Consider the following piece of code (modified from \"PyNumMeth\", Chapter 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "95ab254c-6b37-4e3b-b9c4-04ea3d06809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_and_subtract(iterations):\n",
    "    result = 1.0\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        result += 0.333\n",
    "\n",
    "    for i in range(iterations):\n",
    "        result -= 0.333\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862d73b8-f439-4ee7-ba8e-8cf29347c635",
   "metadata": {},
   "source": [
    "In exact arithmetic (infinite precision) the returned value `result` should always equal exactly `1.0`, independent of the value of `iterations`. We now understand that this probably won't be the case with double precision numbers, even if `iterations = 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53eef10e-d780-4384-81d2-7b9d96eead76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r 9.9999999999999911182158029987476766109467e-01\n"
     ]
    }
   ],
   "source": [
    "r = add_and_subtract(30)\n",
    "print('r', ('%1.40e')%r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0aba375-256a-4c60-9e7f-0c02ae5ff909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r 9.9999999999999733546474089962430298328400e-01\n"
     ]
    }
   ],
   "source": [
    "r = add_and_subtract(100)\n",
    "print('r', ('%1.40e')%r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce527b80-0de7-4a04-8209-43266f5fc5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r 1.0000000000000328626015289046335965394974e+00\n"
     ]
    }
   ],
   "source": [
    "r = add_and_subtract(1000)\n",
    "print('r', ('%1.40e')%r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2bfc2bdf-3581-470b-a300-4ce61ea1290b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r 1.0000000000027613467068476893473416566849e+00\n"
     ]
    }
   ],
   "source": [
    "r = add_and_subtract(100000)\n",
    "print('r', ('%1.40e')%r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f530ce73-db0f-4e23-bddf-cc108b55f26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =         30 error = 8.8818e-16\n",
      "k =        100 error = 2.6645e-15\n",
      "k =       1000 error = 3.2863e-14\n",
      "k =     100000 error = 2.7613e-12\n",
      "k =  100000000 error = 2.2746e-09\n"
     ]
    }
   ],
   "source": [
    "for k in [30, 100, 1000, 100000, 100000000]:\n",
    "    r = add_and_subtract(k)\n",
    "    err = math.fabs(r - 1.0)\n",
    "    print('k =', (('%10d')%k), 'error =', (('%1.4e')%err))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472dbbfd-9b20-4fb8-81ff-89ef404b2e9d",
   "metadata": {},
   "source": [
    "As expected, the more times you perform the add and subtract operations, the more errors you accumulate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40069ad1-1ba6-4a8f-8a41-3e8dd45b589b",
   "metadata": {},
   "source": [
    "The growth of round-off is related to the precision (or number of decimal digits). With fewer decimal digits, round-off errors will grow faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8039c445-14bf-4cd9-8d4e-2044dbc6606f",
   "metadata": {},
   "source": [
    "We repeat our round-off error experiment below with a `float16` variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0ff06ea7-dfe4-4a6f-98ec-2feb72f60537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# float16 version of `add_and_subtract`.\n",
    "def add_and_subtract_f16(iterations):\n",
    "    result = numpy.float16(1.0) # force float16 to be used\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        result += numpy.float16(0.333) # force float16 to be used\n",
    "\n",
    "    for i in range(iterations):\n",
    "        result -= numpy.float16(0.333) # force float16 to be used\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "302d0143-7a9b-4a01-9f2d-d80b67aeb857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =         30 error = 4.8828e-03\n",
      "k =        100 error = 1.2695e-02\n",
      "k =       1000 error = 1.6797e-01\n",
      "k =     100000 error = 1.0250e+03\n",
      "k =  100000000 error = 1.0250e+03\n"
     ]
    }
   ],
   "source": [
    "for k in [30, 100, 1000, 100000, 100000000]:\n",
    "    r_float16 = add_and_subtract_f16(k)\n",
    "    err = math.fabs(r_float16 - 1.0)\n",
    "    print('k =', (('%10d')%k), 'error =', (('%1.4e')%err))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4209db6-b720-4bc1-8fac-9bf5235edcdb",
   "metadata": {},
   "source": [
    "It doesn't take long for the calculation to be completely wrong due to round-off errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb00021-2cfb-44e9-a190-2150d33bc038",
   "metadata": {},
   "source": [
    "### Catestrophic cancellation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9adbac-71b7-482a-9171-d084559e5996",
   "metadata": {},
   "source": [
    "In numerical analysis, catastrophic cancellation (somtimes called subtractive cancellation error) is the phenomenon that subtracting good approximations to two very nearby numbers may yield a very bad approximation to the difference of the original numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4576652-d626-490f-85d3-853520132df6",
   "metadata": {},
   "source": [
    "Subtracting two floating-point numbers that are very close together leaves very few significant digits — a great deal of information is lost. Lower precision numbers have less available digits so the problem is made worse."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d89baa0e-bc7d-40d7-a210-4dc129d806b3",
   "metadata": {},
   "source": [
    "Here is a simple example showing the problem\n",
    "Consider computing $x - y$ using floats (7 decimal digits of accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a6c37870-a12c-4a68-9dc3-7ce328f9f40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x - y = -0.000021\n"
     ]
    }
   ],
   "source": [
    "x = numpy.float32(1.123004)\n",
    "y = numpy.float32(1.123025)\n",
    "\n",
    "v1 = x - y\n",
    "print('x - y =', '%1.6f'%v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c658ee-aaf6-4edd-bd3f-52dd1dc10f59",
   "metadata": {},
   "source": [
    "Our original number had 7 decimal digits, but the difference on has 2.\n",
    "This illustrates that subtracting two floating-point numbers that are very close together leaves very few significant digits — a great deal of information is lost. As the true value is very small, the round-off error becomes much more significant, and sometimes will become much larger than the value being computed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761b1569-0f32-4624-b972-2d93aaa38356",
   "metadata": {},
   "source": [
    "Another common example is solving a quadratic equation, i.e.\n",
    "\n",
    "$$\n",
    "a x^2 + b x + c = 0\n",
    "$$\n",
    "\n",
    "we often quote the way to obtain solutions is to use the formula\n",
    "\n",
    "$$\n",
    "x = \\frac{-b \\pm \\sqrt{b^2 - 4ac} }{2a}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f61148-160b-4e7a-b6ac-f7c45f32c19f",
   "metadata": {},
   "source": [
    "Yielding\n",
    "$$\n",
    "x_1 = \\frac{-b + \\sqrt{b^2 - 4ac} }{2a}.\n",
    "$$\n",
    "$$\n",
    "x_2 = \\frac{-b - \\sqrt{b^2 - 4ac} }{2a}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f720a70-17cd-4662-a4be-f465fe5854ed",
   "metadata": {},
   "source": [
    "Let's suppose that $b > 0$. In this case,\n",
    "there are not subtractive cancellation errors associated with $x_2$ as two terms on the numerator have the sign."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7c494f-4129-413e-9026-d254a2a6a4b9",
   "metadata": {},
   "source": [
    "However, $x_1$ may be subject to subtractive cancellation error if $4ac$ is very small. There is a simple solution to avoid cancellation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9085f6d-fc36-4073-a349-f6cfc58d5ebf",
   "metadata": {},
   "source": [
    "$$\n",
    "x_1 = \\frac{-b + \\sqrt{b^2 - 4ac} }{2a} \\times \\frac{-b - \\sqrt{b^2 - 4ac} }{-b - \\sqrt{b^2 - 4ac}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfa3f5c-c5c6-43e4-b41f-ed2e26b3293b",
   "metadata": {},
   "source": [
    "$$\n",
    "x_1 = \\frac{b^2 - (b^2 - 4ac) }{2a(-b - \\sqrt{b^2 - 4ac})}\n",
    "= \\frac{2c}{(-b - \\sqrt{b^2 - 4ac})}\n",
    "= \\frac{c}{a x_2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357698f8-0426-4313-9e20-572629ddbc60",
   "metadata": {},
   "source": [
    "The above method to compute $x_1$ does not involve subtracting two numbers so there is no risk of catestrophic cancellation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b0d1ab-5d3a-47cb-a3f1-d08a98d3865a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
